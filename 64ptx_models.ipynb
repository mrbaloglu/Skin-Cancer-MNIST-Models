{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "465_Project64.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn6-NylVWrRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.image as img\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBiAEvWcYLLA",
        "colab_type": "code",
        "outputId": "73fafd18-3042-4402-ebf1-38c32e644f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x32xH65gYiYp",
        "colab_type": "code",
        "outputId": "e576b16d-eb35-4a0a-84ad-e3f568910956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/My\\ Drive/465data/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/465data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iqKtlLYJCwD",
        "colab_type": "code",
        "outputId": "96597751-5b45-4c39-817d-bf09f2f6a0ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32ptx_data_n                         HAM10000_images_part_2labels_np.npy\n",
            "HAM10000_images_part_2images_np.npy  images_np_32.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGCsFWh0ZXyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv(\"64ptx_data_n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr5aviudaAh-",
        "colab_type": "code",
        "outputId": "a14d3f40-793e-40a0-daef-bf5522a551c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "print(\"Shape of dataset\", dataset.shape)\n",
        "dataset.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of dataset (9993, 12296)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>12255</th>\n",
              "      <th>12256</th>\n",
              "      <th>12257</th>\n",
              "      <th>12258</th>\n",
              "      <th>12259</th>\n",
              "      <th>12260</th>\n",
              "      <th>12261</th>\n",
              "      <th>12262</th>\n",
              "      <th>12263</th>\n",
              "      <th>12264</th>\n",
              "      <th>12265</th>\n",
              "      <th>12266</th>\n",
              "      <th>12267</th>\n",
              "      <th>12268</th>\n",
              "      <th>12269</th>\n",
              "      <th>12270</th>\n",
              "      <th>12271</th>\n",
              "      <th>12272</th>\n",
              "      <th>12273</th>\n",
              "      <th>12274</th>\n",
              "      <th>12275</th>\n",
              "      <th>12276</th>\n",
              "      <th>12277</th>\n",
              "      <th>12278</th>\n",
              "      <th>12279</th>\n",
              "      <th>12280</th>\n",
              "      <th>12281</th>\n",
              "      <th>12282</th>\n",
              "      <th>12283</th>\n",
              "      <th>12284</th>\n",
              "      <th>12285</th>\n",
              "      <th>12286</th>\n",
              "      <th>12287</th>\n",
              "      <th>image_id</th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>229</td>\n",
              "      <td>132</td>\n",
              "      <td>135</td>\n",
              "      <td>230</td>\n",
              "      <td>126</td>\n",
              "      <td>134</td>\n",
              "      <td>230</td>\n",
              "      <td>124</td>\n",
              "      <td>126</td>\n",
              "      <td>234</td>\n",
              "      <td>130</td>\n",
              "      <td>130</td>\n",
              "      <td>234</td>\n",
              "      <td>132</td>\n",
              "      <td>133</td>\n",
              "      <td>229</td>\n",
              "      <td>128</td>\n",
              "      <td>125</td>\n",
              "      <td>231</td>\n",
              "      <td>128</td>\n",
              "      <td>129</td>\n",
              "      <td>238</td>\n",
              "      <td>134</td>\n",
              "      <td>138</td>\n",
              "      <td>240</td>\n",
              "      <td>139</td>\n",
              "      <td>146</td>\n",
              "      <td>237</td>\n",
              "      <td>130</td>\n",
              "      <td>137</td>\n",
              "      <td>238</td>\n",
              "      <td>131</td>\n",
              "      <td>139</td>\n",
              "      <td>240</td>\n",
              "      <td>136</td>\n",
              "      <td>143</td>\n",
              "      <td>239</td>\n",
              "      <td>135</td>\n",
              "      <td>144</td>\n",
              "      <td>...</td>\n",
              "      <td>225</td>\n",
              "      <td>143</td>\n",
              "      <td>130</td>\n",
              "      <td>224</td>\n",
              "      <td>143</td>\n",
              "      <td>128</td>\n",
              "      <td>221</td>\n",
              "      <td>143</td>\n",
              "      <td>131</td>\n",
              "      <td>224</td>\n",
              "      <td>149</td>\n",
              "      <td>135</td>\n",
              "      <td>223</td>\n",
              "      <td>148</td>\n",
              "      <td>136</td>\n",
              "      <td>222</td>\n",
              "      <td>146</td>\n",
              "      <td>134</td>\n",
              "      <td>223</td>\n",
              "      <td>149</td>\n",
              "      <td>136</td>\n",
              "      <td>222</td>\n",
              "      <td>150</td>\n",
              "      <td>138</td>\n",
              "      <td>219</td>\n",
              "      <td>149</td>\n",
              "      <td>135</td>\n",
              "      <td>218</td>\n",
              "      <td>146</td>\n",
              "      <td>135</td>\n",
              "      <td>212</td>\n",
              "      <td>142</td>\n",
              "      <td>131</td>\n",
              "      <td>ISIC_0024306</td>\n",
              "      <td>HAM_0000550</td>\n",
              "      <td>nv</td>\n",
              "      <td>follow_up</td>\n",
              "      <td>45.0</td>\n",
              "      <td>male</td>\n",
              "      <td>trunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>216</td>\n",
              "      <td>120</td>\n",
              "      <td>133</td>\n",
              "      <td>218</td>\n",
              "      <td>124</td>\n",
              "      <td>139</td>\n",
              "      <td>218</td>\n",
              "      <td>124</td>\n",
              "      <td>134</td>\n",
              "      <td>220</td>\n",
              "      <td>123</td>\n",
              "      <td>135</td>\n",
              "      <td>217</td>\n",
              "      <td>120</td>\n",
              "      <td>135</td>\n",
              "      <td>218</td>\n",
              "      <td>120</td>\n",
              "      <td>135</td>\n",
              "      <td>221</td>\n",
              "      <td>120</td>\n",
              "      <td>134</td>\n",
              "      <td>220</td>\n",
              "      <td>123</td>\n",
              "      <td>134</td>\n",
              "      <td>218</td>\n",
              "      <td>124</td>\n",
              "      <td>134</td>\n",
              "      <td>220</td>\n",
              "      <td>122</td>\n",
              "      <td>128</td>\n",
              "      <td>219</td>\n",
              "      <td>121</td>\n",
              "      <td>133</td>\n",
              "      <td>218</td>\n",
              "      <td>121</td>\n",
              "      <td>132</td>\n",
              "      <td>221</td>\n",
              "      <td>126</td>\n",
              "      <td>138</td>\n",
              "      <td>...</td>\n",
              "      <td>218</td>\n",
              "      <td>141</td>\n",
              "      <td>145</td>\n",
              "      <td>214</td>\n",
              "      <td>140</td>\n",
              "      <td>146</td>\n",
              "      <td>221</td>\n",
              "      <td>146</td>\n",
              "      <td>151</td>\n",
              "      <td>224</td>\n",
              "      <td>147</td>\n",
              "      <td>152</td>\n",
              "      <td>218</td>\n",
              "      <td>144</td>\n",
              "      <td>150</td>\n",
              "      <td>214</td>\n",
              "      <td>142</td>\n",
              "      <td>146</td>\n",
              "      <td>211</td>\n",
              "      <td>140</td>\n",
              "      <td>143</td>\n",
              "      <td>211</td>\n",
              "      <td>138</td>\n",
              "      <td>141</td>\n",
              "      <td>214</td>\n",
              "      <td>139</td>\n",
              "      <td>145</td>\n",
              "      <td>204</td>\n",
              "      <td>133</td>\n",
              "      <td>136</td>\n",
              "      <td>203</td>\n",
              "      <td>132</td>\n",
              "      <td>134</td>\n",
              "      <td>ISIC_0024307</td>\n",
              "      <td>HAM_0003577</td>\n",
              "      <td>nv</td>\n",
              "      <td>follow_up</td>\n",
              "      <td>50.0</td>\n",
              "      <td>male</td>\n",
              "      <td>lower extremity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>246</td>\n",
              "      <td>172</td>\n",
              "      <td>180</td>\n",
              "      <td>246</td>\n",
              "      <td>170</td>\n",
              "      <td>176</td>\n",
              "      <td>246</td>\n",
              "      <td>173</td>\n",
              "      <td>180</td>\n",
              "      <td>246</td>\n",
              "      <td>174</td>\n",
              "      <td>182</td>\n",
              "      <td>247</td>\n",
              "      <td>174</td>\n",
              "      <td>184</td>\n",
              "      <td>247</td>\n",
              "      <td>175</td>\n",
              "      <td>184</td>\n",
              "      <td>247</td>\n",
              "      <td>175</td>\n",
              "      <td>184</td>\n",
              "      <td>247</td>\n",
              "      <td>177</td>\n",
              "      <td>184</td>\n",
              "      <td>248</td>\n",
              "      <td>181</td>\n",
              "      <td>186</td>\n",
              "      <td>248</td>\n",
              "      <td>183</td>\n",
              "      <td>190</td>\n",
              "      <td>248</td>\n",
              "      <td>184</td>\n",
              "      <td>191</td>\n",
              "      <td>248</td>\n",
              "      <td>182</td>\n",
              "      <td>189</td>\n",
              "      <td>248</td>\n",
              "      <td>181</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>215</td>\n",
              "      <td>135</td>\n",
              "      <td>137</td>\n",
              "      <td>216</td>\n",
              "      <td>137</td>\n",
              "      <td>143</td>\n",
              "      <td>214</td>\n",
              "      <td>135</td>\n",
              "      <td>139</td>\n",
              "      <td>212</td>\n",
              "      <td>134</td>\n",
              "      <td>138</td>\n",
              "      <td>210</td>\n",
              "      <td>129</td>\n",
              "      <td>143</td>\n",
              "      <td>210</td>\n",
              "      <td>133</td>\n",
              "      <td>147</td>\n",
              "      <td>215</td>\n",
              "      <td>143</td>\n",
              "      <td>153</td>\n",
              "      <td>219</td>\n",
              "      <td>150</td>\n",
              "      <td>158</td>\n",
              "      <td>219</td>\n",
              "      <td>151</td>\n",
              "      <td>160</td>\n",
              "      <td>217</td>\n",
              "      <td>148</td>\n",
              "      <td>156</td>\n",
              "      <td>216</td>\n",
              "      <td>145</td>\n",
              "      <td>155</td>\n",
              "      <td>ISIC_0024308</td>\n",
              "      <td>HAM_0001477</td>\n",
              "      <td>nv</td>\n",
              "      <td>follow_up</td>\n",
              "      <td>55.0</td>\n",
              "      <td>female</td>\n",
              "      <td>trunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>207</td>\n",
              "      <td>118</td>\n",
              "      <td>134</td>\n",
              "      <td>211</td>\n",
              "      <td>120</td>\n",
              "      <td>134</td>\n",
              "      <td>207</td>\n",
              "      <td>116</td>\n",
              "      <td>131</td>\n",
              "      <td>208</td>\n",
              "      <td>117</td>\n",
              "      <td>134</td>\n",
              "      <td>212</td>\n",
              "      <td>123</td>\n",
              "      <td>138</td>\n",
              "      <td>211</td>\n",
              "      <td>123</td>\n",
              "      <td>139</td>\n",
              "      <td>211</td>\n",
              "      <td>127</td>\n",
              "      <td>140</td>\n",
              "      <td>213</td>\n",
              "      <td>125</td>\n",
              "      <td>141</td>\n",
              "      <td>214</td>\n",
              "      <td>127</td>\n",
              "      <td>142</td>\n",
              "      <td>213</td>\n",
              "      <td>126</td>\n",
              "      <td>141</td>\n",
              "      <td>213</td>\n",
              "      <td>124</td>\n",
              "      <td>142</td>\n",
              "      <td>213</td>\n",
              "      <td>123</td>\n",
              "      <td>139</td>\n",
              "      <td>212</td>\n",
              "      <td>123</td>\n",
              "      <td>139</td>\n",
              "      <td>...</td>\n",
              "      <td>201</td>\n",
              "      <td>132</td>\n",
              "      <td>129</td>\n",
              "      <td>198</td>\n",
              "      <td>128</td>\n",
              "      <td>122</td>\n",
              "      <td>195</td>\n",
              "      <td>124</td>\n",
              "      <td>117</td>\n",
              "      <td>196</td>\n",
              "      <td>127</td>\n",
              "      <td>120</td>\n",
              "      <td>194</td>\n",
              "      <td>121</td>\n",
              "      <td>119</td>\n",
              "      <td>193</td>\n",
              "      <td>121</td>\n",
              "      <td>119</td>\n",
              "      <td>193</td>\n",
              "      <td>123</td>\n",
              "      <td>118</td>\n",
              "      <td>190</td>\n",
              "      <td>120</td>\n",
              "      <td>119</td>\n",
              "      <td>189</td>\n",
              "      <td>118</td>\n",
              "      <td>121</td>\n",
              "      <td>189</td>\n",
              "      <td>120</td>\n",
              "      <td>124</td>\n",
              "      <td>189</td>\n",
              "      <td>124</td>\n",
              "      <td>127</td>\n",
              "      <td>ISIC_0024309</td>\n",
              "      <td>HAM_0000484</td>\n",
              "      <td>nv</td>\n",
              "      <td>follow_up</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>trunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>71</td>\n",
              "      <td>32</td>\n",
              "      <td>37</td>\n",
              "      <td>70</td>\n",
              "      <td>32</td>\n",
              "      <td>39</td>\n",
              "      <td>63</td>\n",
              "      <td>25</td>\n",
              "      <td>30</td>\n",
              "      <td>94</td>\n",
              "      <td>45</td>\n",
              "      <td>51</td>\n",
              "      <td>165</td>\n",
              "      <td>105</td>\n",
              "      <td>115</td>\n",
              "      <td>195</td>\n",
              "      <td>133</td>\n",
              "      <td>140</td>\n",
              "      <td>208</td>\n",
              "      <td>149</td>\n",
              "      <td>153</td>\n",
              "      <td>208</td>\n",
              "      <td>144</td>\n",
              "      <td>152</td>\n",
              "      <td>210</td>\n",
              "      <td>145</td>\n",
              "      <td>160</td>\n",
              "      <td>210</td>\n",
              "      <td>146</td>\n",
              "      <td>163</td>\n",
              "      <td>209</td>\n",
              "      <td>146</td>\n",
              "      <td>157</td>\n",
              "      <td>214</td>\n",
              "      <td>154</td>\n",
              "      <td>164</td>\n",
              "      <td>214</td>\n",
              "      <td>159</td>\n",
              "      <td>167</td>\n",
              "      <td>...</td>\n",
              "      <td>206</td>\n",
              "      <td>137</td>\n",
              "      <td>114</td>\n",
              "      <td>204</td>\n",
              "      <td>127</td>\n",
              "      <td>103</td>\n",
              "      <td>204</td>\n",
              "      <td>122</td>\n",
              "      <td>118</td>\n",
              "      <td>205</td>\n",
              "      <td>132</td>\n",
              "      <td>137</td>\n",
              "      <td>201</td>\n",
              "      <td>120</td>\n",
              "      <td>104</td>\n",
              "      <td>203</td>\n",
              "      <td>124</td>\n",
              "      <td>129</td>\n",
              "      <td>194</td>\n",
              "      <td>132</td>\n",
              "      <td>146</td>\n",
              "      <td>159</td>\n",
              "      <td>102</td>\n",
              "      <td>98</td>\n",
              "      <td>93</td>\n",
              "      <td>47</td>\n",
              "      <td>51</td>\n",
              "      <td>70</td>\n",
              "      <td>30</td>\n",
              "      <td>42</td>\n",
              "      <td>73</td>\n",
              "      <td>33</td>\n",
              "      <td>44</td>\n",
              "      <td>ISIC_0024310</td>\n",
              "      <td>HAM_0003350</td>\n",
              "      <td>mel</td>\n",
              "      <td>histo</td>\n",
              "      <td>60.0</td>\n",
              "      <td>male</td>\n",
              "      <td>chest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 12296 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0    0    1    2  ...    dx_type   age     sex     localization\n",
              "0           0  229  132  135  ...  follow_up  45.0    male            trunk\n",
              "1           1  216  120  133  ...  follow_up  50.0    male  lower extremity\n",
              "2           2  246  172  180  ...  follow_up  55.0  female            trunk\n",
              "3           3  207  118  134  ...  follow_up  40.0    male            trunk\n",
              "4           4   71   32   37  ...      histo  60.0    male            chest\n",
              "\n",
              "[5 rows x 12296 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shHco0WgJU3O",
        "colab_type": "code",
        "outputId": "0c4e867d-fd59-455c-e4d1-0c42f057143b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "X = dataset.drop(columns = [\"Unnamed: 0\",\"dx\",\"image_id\",\"lesion_id\",\"dx\",\"dx_type\",\"age\",\"sex\",\"localization\"])\n",
        "print(\"Shape of X\", X.shape)\n",
        "X.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X (9993, 12288)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>12248</th>\n",
              "      <th>12249</th>\n",
              "      <th>12250</th>\n",
              "      <th>12251</th>\n",
              "      <th>12252</th>\n",
              "      <th>12253</th>\n",
              "      <th>12254</th>\n",
              "      <th>12255</th>\n",
              "      <th>12256</th>\n",
              "      <th>12257</th>\n",
              "      <th>12258</th>\n",
              "      <th>12259</th>\n",
              "      <th>12260</th>\n",
              "      <th>12261</th>\n",
              "      <th>12262</th>\n",
              "      <th>12263</th>\n",
              "      <th>12264</th>\n",
              "      <th>12265</th>\n",
              "      <th>12266</th>\n",
              "      <th>12267</th>\n",
              "      <th>12268</th>\n",
              "      <th>12269</th>\n",
              "      <th>12270</th>\n",
              "      <th>12271</th>\n",
              "      <th>12272</th>\n",
              "      <th>12273</th>\n",
              "      <th>12274</th>\n",
              "      <th>12275</th>\n",
              "      <th>12276</th>\n",
              "      <th>12277</th>\n",
              "      <th>12278</th>\n",
              "      <th>12279</th>\n",
              "      <th>12280</th>\n",
              "      <th>12281</th>\n",
              "      <th>12282</th>\n",
              "      <th>12283</th>\n",
              "      <th>12284</th>\n",
              "      <th>12285</th>\n",
              "      <th>12286</th>\n",
              "      <th>12287</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>229</td>\n",
              "      <td>132</td>\n",
              "      <td>135</td>\n",
              "      <td>230</td>\n",
              "      <td>126</td>\n",
              "      <td>134</td>\n",
              "      <td>230</td>\n",
              "      <td>124</td>\n",
              "      <td>126</td>\n",
              "      <td>234</td>\n",
              "      <td>130</td>\n",
              "      <td>130</td>\n",
              "      <td>234</td>\n",
              "      <td>132</td>\n",
              "      <td>133</td>\n",
              "      <td>229</td>\n",
              "      <td>128</td>\n",
              "      <td>125</td>\n",
              "      <td>231</td>\n",
              "      <td>128</td>\n",
              "      <td>129</td>\n",
              "      <td>238</td>\n",
              "      <td>134</td>\n",
              "      <td>138</td>\n",
              "      <td>240</td>\n",
              "      <td>139</td>\n",
              "      <td>146</td>\n",
              "      <td>237</td>\n",
              "      <td>130</td>\n",
              "      <td>137</td>\n",
              "      <td>238</td>\n",
              "      <td>131</td>\n",
              "      <td>139</td>\n",
              "      <td>240</td>\n",
              "      <td>136</td>\n",
              "      <td>143</td>\n",
              "      <td>239</td>\n",
              "      <td>135</td>\n",
              "      <td>144</td>\n",
              "      <td>235</td>\n",
              "      <td>...</td>\n",
              "      <td>135</td>\n",
              "      <td>225</td>\n",
              "      <td>144</td>\n",
              "      <td>129</td>\n",
              "      <td>223</td>\n",
              "      <td>138</td>\n",
              "      <td>124</td>\n",
              "      <td>225</td>\n",
              "      <td>143</td>\n",
              "      <td>130</td>\n",
              "      <td>224</td>\n",
              "      <td>143</td>\n",
              "      <td>128</td>\n",
              "      <td>221</td>\n",
              "      <td>143</td>\n",
              "      <td>131</td>\n",
              "      <td>224</td>\n",
              "      <td>149</td>\n",
              "      <td>135</td>\n",
              "      <td>223</td>\n",
              "      <td>148</td>\n",
              "      <td>136</td>\n",
              "      <td>222</td>\n",
              "      <td>146</td>\n",
              "      <td>134</td>\n",
              "      <td>223</td>\n",
              "      <td>149</td>\n",
              "      <td>136</td>\n",
              "      <td>222</td>\n",
              "      <td>150</td>\n",
              "      <td>138</td>\n",
              "      <td>219</td>\n",
              "      <td>149</td>\n",
              "      <td>135</td>\n",
              "      <td>218</td>\n",
              "      <td>146</td>\n",
              "      <td>135</td>\n",
              "      <td>212</td>\n",
              "      <td>142</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>216</td>\n",
              "      <td>120</td>\n",
              "      <td>133</td>\n",
              "      <td>218</td>\n",
              "      <td>124</td>\n",
              "      <td>139</td>\n",
              "      <td>218</td>\n",
              "      <td>124</td>\n",
              "      <td>134</td>\n",
              "      <td>220</td>\n",
              "      <td>123</td>\n",
              "      <td>135</td>\n",
              "      <td>217</td>\n",
              "      <td>120</td>\n",
              "      <td>135</td>\n",
              "      <td>218</td>\n",
              "      <td>120</td>\n",
              "      <td>135</td>\n",
              "      <td>221</td>\n",
              "      <td>120</td>\n",
              "      <td>134</td>\n",
              "      <td>220</td>\n",
              "      <td>123</td>\n",
              "      <td>134</td>\n",
              "      <td>218</td>\n",
              "      <td>124</td>\n",
              "      <td>134</td>\n",
              "      <td>220</td>\n",
              "      <td>122</td>\n",
              "      <td>128</td>\n",
              "      <td>219</td>\n",
              "      <td>121</td>\n",
              "      <td>133</td>\n",
              "      <td>218</td>\n",
              "      <td>121</td>\n",
              "      <td>132</td>\n",
              "      <td>221</td>\n",
              "      <td>126</td>\n",
              "      <td>138</td>\n",
              "      <td>221</td>\n",
              "      <td>...</td>\n",
              "      <td>154</td>\n",
              "      <td>225</td>\n",
              "      <td>149</td>\n",
              "      <td>155</td>\n",
              "      <td>221</td>\n",
              "      <td>143</td>\n",
              "      <td>148</td>\n",
              "      <td>218</td>\n",
              "      <td>141</td>\n",
              "      <td>145</td>\n",
              "      <td>214</td>\n",
              "      <td>140</td>\n",
              "      <td>146</td>\n",
              "      <td>221</td>\n",
              "      <td>146</td>\n",
              "      <td>151</td>\n",
              "      <td>224</td>\n",
              "      <td>147</td>\n",
              "      <td>152</td>\n",
              "      <td>218</td>\n",
              "      <td>144</td>\n",
              "      <td>150</td>\n",
              "      <td>214</td>\n",
              "      <td>142</td>\n",
              "      <td>146</td>\n",
              "      <td>211</td>\n",
              "      <td>140</td>\n",
              "      <td>143</td>\n",
              "      <td>211</td>\n",
              "      <td>138</td>\n",
              "      <td>141</td>\n",
              "      <td>214</td>\n",
              "      <td>139</td>\n",
              "      <td>145</td>\n",
              "      <td>204</td>\n",
              "      <td>133</td>\n",
              "      <td>136</td>\n",
              "      <td>203</td>\n",
              "      <td>132</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>246</td>\n",
              "      <td>172</td>\n",
              "      <td>180</td>\n",
              "      <td>246</td>\n",
              "      <td>170</td>\n",
              "      <td>176</td>\n",
              "      <td>246</td>\n",
              "      <td>173</td>\n",
              "      <td>180</td>\n",
              "      <td>246</td>\n",
              "      <td>174</td>\n",
              "      <td>182</td>\n",
              "      <td>247</td>\n",
              "      <td>174</td>\n",
              "      <td>184</td>\n",
              "      <td>247</td>\n",
              "      <td>175</td>\n",
              "      <td>184</td>\n",
              "      <td>247</td>\n",
              "      <td>175</td>\n",
              "      <td>184</td>\n",
              "      <td>247</td>\n",
              "      <td>177</td>\n",
              "      <td>184</td>\n",
              "      <td>248</td>\n",
              "      <td>181</td>\n",
              "      <td>186</td>\n",
              "      <td>248</td>\n",
              "      <td>183</td>\n",
              "      <td>190</td>\n",
              "      <td>248</td>\n",
              "      <td>184</td>\n",
              "      <td>191</td>\n",
              "      <td>248</td>\n",
              "      <td>182</td>\n",
              "      <td>189</td>\n",
              "      <td>248</td>\n",
              "      <td>181</td>\n",
              "      <td>187</td>\n",
              "      <td>248</td>\n",
              "      <td>...</td>\n",
              "      <td>151</td>\n",
              "      <td>221</td>\n",
              "      <td>147</td>\n",
              "      <td>151</td>\n",
              "      <td>216</td>\n",
              "      <td>140</td>\n",
              "      <td>145</td>\n",
              "      <td>215</td>\n",
              "      <td>135</td>\n",
              "      <td>137</td>\n",
              "      <td>216</td>\n",
              "      <td>137</td>\n",
              "      <td>143</td>\n",
              "      <td>214</td>\n",
              "      <td>135</td>\n",
              "      <td>139</td>\n",
              "      <td>212</td>\n",
              "      <td>134</td>\n",
              "      <td>138</td>\n",
              "      <td>210</td>\n",
              "      <td>129</td>\n",
              "      <td>143</td>\n",
              "      <td>210</td>\n",
              "      <td>133</td>\n",
              "      <td>147</td>\n",
              "      <td>215</td>\n",
              "      <td>143</td>\n",
              "      <td>153</td>\n",
              "      <td>219</td>\n",
              "      <td>150</td>\n",
              "      <td>158</td>\n",
              "      <td>219</td>\n",
              "      <td>151</td>\n",
              "      <td>160</td>\n",
              "      <td>217</td>\n",
              "      <td>148</td>\n",
              "      <td>156</td>\n",
              "      <td>216</td>\n",
              "      <td>145</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>207</td>\n",
              "      <td>118</td>\n",
              "      <td>134</td>\n",
              "      <td>211</td>\n",
              "      <td>120</td>\n",
              "      <td>134</td>\n",
              "      <td>207</td>\n",
              "      <td>116</td>\n",
              "      <td>131</td>\n",
              "      <td>208</td>\n",
              "      <td>117</td>\n",
              "      <td>134</td>\n",
              "      <td>212</td>\n",
              "      <td>123</td>\n",
              "      <td>138</td>\n",
              "      <td>211</td>\n",
              "      <td>123</td>\n",
              "      <td>139</td>\n",
              "      <td>211</td>\n",
              "      <td>127</td>\n",
              "      <td>140</td>\n",
              "      <td>213</td>\n",
              "      <td>125</td>\n",
              "      <td>141</td>\n",
              "      <td>214</td>\n",
              "      <td>127</td>\n",
              "      <td>142</td>\n",
              "      <td>213</td>\n",
              "      <td>126</td>\n",
              "      <td>141</td>\n",
              "      <td>213</td>\n",
              "      <td>124</td>\n",
              "      <td>142</td>\n",
              "      <td>213</td>\n",
              "      <td>123</td>\n",
              "      <td>139</td>\n",
              "      <td>212</td>\n",
              "      <td>123</td>\n",
              "      <td>139</td>\n",
              "      <td>214</td>\n",
              "      <td>...</td>\n",
              "      <td>129</td>\n",
              "      <td>199</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>199</td>\n",
              "      <td>128</td>\n",
              "      <td>127</td>\n",
              "      <td>201</td>\n",
              "      <td>132</td>\n",
              "      <td>129</td>\n",
              "      <td>198</td>\n",
              "      <td>128</td>\n",
              "      <td>122</td>\n",
              "      <td>195</td>\n",
              "      <td>124</td>\n",
              "      <td>117</td>\n",
              "      <td>196</td>\n",
              "      <td>127</td>\n",
              "      <td>120</td>\n",
              "      <td>194</td>\n",
              "      <td>121</td>\n",
              "      <td>119</td>\n",
              "      <td>193</td>\n",
              "      <td>121</td>\n",
              "      <td>119</td>\n",
              "      <td>193</td>\n",
              "      <td>123</td>\n",
              "      <td>118</td>\n",
              "      <td>190</td>\n",
              "      <td>120</td>\n",
              "      <td>119</td>\n",
              "      <td>189</td>\n",
              "      <td>118</td>\n",
              "      <td>121</td>\n",
              "      <td>189</td>\n",
              "      <td>120</td>\n",
              "      <td>124</td>\n",
              "      <td>189</td>\n",
              "      <td>124</td>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71</td>\n",
              "      <td>32</td>\n",
              "      <td>37</td>\n",
              "      <td>70</td>\n",
              "      <td>32</td>\n",
              "      <td>39</td>\n",
              "      <td>63</td>\n",
              "      <td>25</td>\n",
              "      <td>30</td>\n",
              "      <td>94</td>\n",
              "      <td>45</td>\n",
              "      <td>51</td>\n",
              "      <td>165</td>\n",
              "      <td>105</td>\n",
              "      <td>115</td>\n",
              "      <td>195</td>\n",
              "      <td>133</td>\n",
              "      <td>140</td>\n",
              "      <td>208</td>\n",
              "      <td>149</td>\n",
              "      <td>153</td>\n",
              "      <td>208</td>\n",
              "      <td>144</td>\n",
              "      <td>152</td>\n",
              "      <td>210</td>\n",
              "      <td>145</td>\n",
              "      <td>160</td>\n",
              "      <td>210</td>\n",
              "      <td>146</td>\n",
              "      <td>163</td>\n",
              "      <td>209</td>\n",
              "      <td>146</td>\n",
              "      <td>157</td>\n",
              "      <td>214</td>\n",
              "      <td>154</td>\n",
              "      <td>164</td>\n",
              "      <td>214</td>\n",
              "      <td>159</td>\n",
              "      <td>167</td>\n",
              "      <td>215</td>\n",
              "      <td>...</td>\n",
              "      <td>131</td>\n",
              "      <td>214</td>\n",
              "      <td>153</td>\n",
              "      <td>159</td>\n",
              "      <td>209</td>\n",
              "      <td>149</td>\n",
              "      <td>145</td>\n",
              "      <td>206</td>\n",
              "      <td>137</td>\n",
              "      <td>114</td>\n",
              "      <td>204</td>\n",
              "      <td>127</td>\n",
              "      <td>103</td>\n",
              "      <td>204</td>\n",
              "      <td>122</td>\n",
              "      <td>118</td>\n",
              "      <td>205</td>\n",
              "      <td>132</td>\n",
              "      <td>137</td>\n",
              "      <td>201</td>\n",
              "      <td>120</td>\n",
              "      <td>104</td>\n",
              "      <td>203</td>\n",
              "      <td>124</td>\n",
              "      <td>129</td>\n",
              "      <td>194</td>\n",
              "      <td>132</td>\n",
              "      <td>146</td>\n",
              "      <td>159</td>\n",
              "      <td>102</td>\n",
              "      <td>98</td>\n",
              "      <td>93</td>\n",
              "      <td>47</td>\n",
              "      <td>51</td>\n",
              "      <td>70</td>\n",
              "      <td>30</td>\n",
              "      <td>42</td>\n",
              "      <td>73</td>\n",
              "      <td>33</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 12288 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4    5  ...  12282  12283  12284  12285  12286  12287\n",
              "0  229  132  135  230  126  134  ...    218    146    135    212    142    131\n",
              "1  216  120  133  218  124  139  ...    204    133    136    203    132    134\n",
              "2  246  172  180  246  170  176  ...    217    148    156    216    145    155\n",
              "3  207  118  134  211  120  134  ...    189    120    124    189    124    127\n",
              "4   71   32   37   70   32   39  ...     70     30     42     73     33     44\n",
              "\n",
              "[5 rows x 12288 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INXUUB4qLg7o",
        "colab_type": "code",
        "outputId": "ba31e26b-b168-4e95-ae89-db1aa585f870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "Y = dataset[\"dx\"]\n",
        "Y = pd.get_dummies(Y)\n",
        "print(\"Shape of Y\", Y.shape)\n",
        "Y.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Y (9993, 7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>akiec</th>\n",
              "      <th>bcc</th>\n",
              "      <th>bkl</th>\n",
              "      <th>df</th>\n",
              "      <th>mel</th>\n",
              "      <th>nv</th>\n",
              "      <th>vasc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   akiec  bcc  bkl  df  mel  nv  vasc\n",
              "0      0    0    0   0    0   1     0\n",
              "1      0    0    0   0    0   1     0\n",
              "2      0    0    0   0    0   1     0\n",
              "3      0    0    0   0    0   1     0\n",
              "4      0    0    0   0    1   0     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiwaYj9Mcj5G",
        "colab_type": "code",
        "outputId": "86f3f500-ff3b-49e7-baf4-c25f2c81a1fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE1FzwJE8frE",
        "colab_type": "code",
        "outputId": "a13f01b8-370b-41ec-92d1-8f76d31a4251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state = 42)\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train_flat shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test_flat shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training examples = 8494\n",
            "number of test examples = 1499\n",
            "X_train_flat shape: (8494, 12288)\n",
            "Y_train shape: (8494, 7)\n",
            "X_test_flat shape: (1499, 12288)\n",
            "Y_test shape: (1499, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z04BiOiwM1nn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.values\n",
        "Y_train = Y_train.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk6ZysigiUkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LRModel1(input_shape = (3072,), classes = 7):\n",
        "    X_input = Input(input_shape)\n",
        "    X = BatchNormalization()(X_input)\n",
        "    X = Dense(input_shape, activation='sigmoid', name = \"sigmoid_activation\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, input_shape=input_shape, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    model = Model(inputs = X_input, outputs = X, name='LogisticRegression')\n",
        "    return model\n",
        "\n",
        "def LRModel2(input_shape = (3072,), classes = 7):\n",
        "    X_input = Input(input_shape)\n",
        "    X = BatchNormalization()(X_input)\n",
        "    X = Dense(classes, input_shape=input_shape, activation='sigmoid', name = \"sigmoid_activation\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Activation(\"softmax\")(X)\n",
        "    model = Model(inputs = X_input, outputs = X, name='LogisticRegression')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhjujZxQkBQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LRModel2(input_shape = (12288,), classes = 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnE-VAFEkchs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD, Adam\n",
        "adam = Adam(lr= 0.0005)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSe6Fec-kg9_",
        "colab_type": "code",
        "outputId": "bbf062ae-f552-422b-ab0e-4fffa33b595f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, Y_train, epochs = 200, batch_size = 32)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "8494/8494 [==============================] - 4s 471us/step - loss: 1.6551 - accuracy: 0.5039\n",
            "Epoch 2/200\n",
            "8494/8494 [==============================] - 4s 435us/step - loss: 1.4628 - accuracy: 0.5637\n",
            "Epoch 3/200\n",
            "8494/8494 [==============================] - 4s 431us/step - loss: 1.4492 - accuracy: 0.5812\n",
            "Epoch 4/200\n",
            "8494/8494 [==============================] - 4s 439us/step - loss: 1.4425 - accuracy: 0.5963\n",
            "Epoch 5/200\n",
            "8494/8494 [==============================] - 4s 453us/step - loss: 1.4377 - accuracy: 0.5834\n",
            "Epoch 6/200\n",
            "8494/8494 [==============================] - 4s 448us/step - loss: 1.4317 - accuracy: 0.5934\n",
            "Epoch 7/200\n",
            "8494/8494 [==============================] - 4s 455us/step - loss: 1.4293 - accuracy: 0.6164\n",
            "Epoch 8/200\n",
            "8494/8494 [==============================] - 4s 442us/step - loss: 1.4295 - accuracy: 0.6317\n",
            "Epoch 9/200\n",
            "8494/8494 [==============================] - 4s 434us/step - loss: 1.4286 - accuracy: 0.6334\n",
            "Epoch 10/200\n",
            "8494/8494 [==============================] - 4s 439us/step - loss: 1.4232 - accuracy: 0.6414\n",
            "Epoch 11/200\n",
            "8494/8494 [==============================] - 4s 438us/step - loss: 1.4196 - accuracy: 0.6360\n",
            "Epoch 12/200\n",
            "8494/8494 [==============================] - 4s 430us/step - loss: 1.4196 - accuracy: 0.6435\n",
            "Epoch 13/200\n",
            "8494/8494 [==============================] - 4s 433us/step - loss: 1.4170 - accuracy: 0.6547\n",
            "Epoch 14/200\n",
            "8494/8494 [==============================] - 4s 420us/step - loss: 1.4211 - accuracy: 0.6575\n",
            "Epoch 15/200\n",
            "8494/8494 [==============================] - 4s 430us/step - loss: 1.4164 - accuracy: 0.6535\n",
            "Epoch 16/200\n",
            "8494/8494 [==============================] - 4s 438us/step - loss: 1.4172 - accuracy: 0.6512\n",
            "Epoch 17/200\n",
            "8494/8494 [==============================] - 4s 433us/step - loss: 1.4135 - accuracy: 0.6394\n",
            "Epoch 18/200\n",
            "8494/8494 [==============================] - 4s 438us/step - loss: 1.4116 - accuracy: 0.6500\n",
            "Epoch 19/200\n",
            "8494/8494 [==============================] - 4s 437us/step - loss: 1.4118 - accuracy: 0.6611\n",
            "Epoch 20/200\n",
            "8494/8494 [==============================] - 4s 431us/step - loss: 1.4138 - accuracy: 0.6582\n",
            "Epoch 21/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.4107 - accuracy: 0.6622\n",
            "Epoch 22/200\n",
            "8494/8494 [==============================] - 4s 426us/step - loss: 1.4106 - accuracy: 0.6427\n",
            "Epoch 23/200\n",
            "8494/8494 [==============================] - 4s 427us/step - loss: 1.4070 - accuracy: 0.6674\n",
            "Epoch 24/200\n",
            "8494/8494 [==============================] - 4s 435us/step - loss: 1.4083 - accuracy: 0.6708\n",
            "Epoch 25/200\n",
            "8494/8494 [==============================] - 4s 431us/step - loss: 1.4068 - accuracy: 0.6540\n",
            "Epoch 26/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.4043 - accuracy: 0.6655\n",
            "Epoch 27/200\n",
            "8494/8494 [==============================] - 4s 432us/step - loss: 1.4070 - accuracy: 0.6642\n",
            "Epoch 28/200\n",
            "8494/8494 [==============================] - 4s 426us/step - loss: 1.4045 - accuracy: 0.6588\n",
            "Epoch 29/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.4073 - accuracy: 0.6483\n",
            "Epoch 30/200\n",
            "8494/8494 [==============================] - 4s 427us/step - loss: 1.4049 - accuracy: 0.6432\n",
            "Epoch 31/200\n",
            "8494/8494 [==============================] - 4s 424us/step - loss: 1.4042 - accuracy: 0.6549\n",
            "Epoch 32/200\n",
            "8494/8494 [==============================] - 4s 426us/step - loss: 1.4012 - accuracy: 0.6532\n",
            "Epoch 33/200\n",
            "8494/8494 [==============================] - 4s 422us/step - loss: 1.4012 - accuracy: 0.6731\n",
            "Epoch 34/200\n",
            "8494/8494 [==============================] - 4s 431us/step - loss: 1.3994 - accuracy: 0.6775\n",
            "Epoch 35/200\n",
            "8494/8494 [==============================] - 4s 426us/step - loss: 1.3978 - accuracy: 0.6711\n",
            "Epoch 36/200\n",
            "8494/8494 [==============================] - 4s 430us/step - loss: 1.4028 - accuracy: 0.6547\n",
            "Epoch 37/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3999 - accuracy: 0.6601\n",
            "Epoch 38/200\n",
            "8494/8494 [==============================] - 4s 430us/step - loss: 1.3973 - accuracy: 0.6653\n",
            "Epoch 39/200\n",
            "8494/8494 [==============================] - 4s 430us/step - loss: 1.3960 - accuracy: 0.6603\n",
            "Epoch 40/200\n",
            "8494/8494 [==============================] - 4s 433us/step - loss: 1.3967 - accuracy: 0.6693\n",
            "Epoch 41/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3944 - accuracy: 0.6655\n",
            "Epoch 42/200\n",
            "8494/8494 [==============================] - 4s 432us/step - loss: 1.3968 - accuracy: 0.6609\n",
            "Epoch 43/200\n",
            "8494/8494 [==============================] - 4s 426us/step - loss: 1.3970 - accuracy: 0.6645\n",
            "Epoch 44/200\n",
            "8494/8494 [==============================] - 4s 436us/step - loss: 1.3931 - accuracy: 0.6724\n",
            "Epoch 45/200\n",
            "8494/8494 [==============================] - 4s 430us/step - loss: 1.3928 - accuracy: 0.6656\n",
            "Epoch 46/200\n",
            "8494/8494 [==============================] - 4s 435us/step - loss: 1.3920 - accuracy: 0.6623\n",
            "Epoch 47/200\n",
            "8494/8494 [==============================] - 4s 444us/step - loss: 1.3899 - accuracy: 0.6732\n",
            "Epoch 48/200\n",
            "8494/8494 [==============================] - 4s 431us/step - loss: 1.3892 - accuracy: 0.6757\n",
            "Epoch 49/200\n",
            "8494/8494 [==============================] - 4s 432us/step - loss: 1.3877 - accuracy: 0.6659\n",
            "Epoch 50/200\n",
            "8494/8494 [==============================] - 4s 428us/step - loss: 1.3906 - accuracy: 0.6732\n",
            "Epoch 51/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3888 - accuracy: 0.6708\n",
            "Epoch 52/200\n",
            "8494/8494 [==============================] - 4s 428us/step - loss: 1.3889 - accuracy: 0.6777\n",
            "Epoch 53/200\n",
            "8494/8494 [==============================] - 4s 421us/step - loss: 1.3910 - accuracy: 0.6729\n",
            "Epoch 54/200\n",
            "8494/8494 [==============================] - 4s 417us/step - loss: 1.3929 - accuracy: 0.6719\n",
            "Epoch 55/200\n",
            "8494/8494 [==============================] - 4s 419us/step - loss: 1.3891 - accuracy: 0.6752\n",
            "Epoch 56/200\n",
            "8494/8494 [==============================] - 4s 422us/step - loss: 1.3872 - accuracy: 0.6785\n",
            "Epoch 57/200\n",
            "8494/8494 [==============================] - 4s 431us/step - loss: 1.3899 - accuracy: 0.6669\n",
            "Epoch 58/200\n",
            "8494/8494 [==============================] - 4s 443us/step - loss: 1.3868 - accuracy: 0.6787\n",
            "Epoch 59/200\n",
            "8494/8494 [==============================] - 4s 430us/step - loss: 1.3896 - accuracy: 0.6622\n",
            "Epoch 60/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3839 - accuracy: 0.6741\n",
            "Epoch 61/200\n",
            "8494/8494 [==============================] - 4s 421us/step - loss: 1.3872 - accuracy: 0.6768\n",
            "Epoch 62/200\n",
            "8494/8494 [==============================] - 4s 426us/step - loss: 1.3839 - accuracy: 0.6833\n",
            "Epoch 63/200\n",
            "8494/8494 [==============================] - 4s 426us/step - loss: 1.3910 - accuracy: 0.6853\n",
            "Epoch 64/200\n",
            "8494/8494 [==============================] - 4s 419us/step - loss: 1.3825 - accuracy: 0.6797\n",
            "Epoch 65/200\n",
            "8494/8494 [==============================] - 4s 419us/step - loss: 1.3815 - accuracy: 0.6900\n",
            "Epoch 66/200\n",
            "8494/8494 [==============================] - 4s 440us/step - loss: 1.3840 - accuracy: 0.6862\n",
            "Epoch 67/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3825 - accuracy: 0.6820\n",
            "Epoch 68/200\n",
            "8494/8494 [==============================] - 4s 424us/step - loss: 1.3854 - accuracy: 0.6815\n",
            "Epoch 69/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3831 - accuracy: 0.6824\n",
            "Epoch 70/200\n",
            "8494/8494 [==============================] - 4s 433us/step - loss: 1.3814 - accuracy: 0.6827\n",
            "Epoch 71/200\n",
            "8494/8494 [==============================] - 4s 419us/step - loss: 1.3822 - accuracy: 0.6766\n",
            "Epoch 72/200\n",
            "8494/8494 [==============================] - 4s 421us/step - loss: 1.3790 - accuracy: 0.6808\n",
            "Epoch 73/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3782 - accuracy: 0.6804\n",
            "Epoch 74/200\n",
            "8494/8494 [==============================] - 4s 420us/step - loss: 1.3811 - accuracy: 0.6761\n",
            "Epoch 75/200\n",
            "8494/8494 [==============================] - 4s 424us/step - loss: 1.3837 - accuracy: 0.6692\n",
            "Epoch 76/200\n",
            "8494/8494 [==============================] - 4s 436us/step - loss: 1.3775 - accuracy: 0.6740\n",
            "Epoch 77/200\n",
            "8494/8494 [==============================] - 4s 431us/step - loss: 1.3774 - accuracy: 0.6899\n",
            "Epoch 78/200\n",
            "8494/8494 [==============================] - 4s 431us/step - loss: 1.3818 - accuracy: 0.6799\n",
            "Epoch 79/200\n",
            "8494/8494 [==============================] - 4s 414us/step - loss: 1.3794 - accuracy: 0.6758\n",
            "Epoch 80/200\n",
            "8494/8494 [==============================] - 4s 416us/step - loss: 1.3795 - accuracy: 0.6897\n",
            "Epoch 81/200\n",
            "8494/8494 [==============================] - 4s 420us/step - loss: 1.3740 - accuracy: 0.6859\n",
            "Epoch 82/200\n",
            "8494/8494 [==============================] - 4s 508us/step - loss: 1.3762 - accuracy: 0.6862\n",
            "Epoch 83/200\n",
            "8494/8494 [==============================] - 4s 500us/step - loss: 1.3764 - accuracy: 0.6914\n",
            "Epoch 84/200\n",
            "8494/8494 [==============================] - 4s 424us/step - loss: 1.3810 - accuracy: 0.6827\n",
            "Epoch 85/200\n",
            "8494/8494 [==============================] - 4s 424us/step - loss: 1.3744 - accuracy: 0.6953\n",
            "Epoch 86/200\n",
            "8494/8494 [==============================] - 4s 421us/step - loss: 1.3754 - accuracy: 0.6872\n",
            "Epoch 87/200\n",
            "8494/8494 [==============================] - 4s 414us/step - loss: 1.3747 - accuracy: 0.6848\n",
            "Epoch 88/200\n",
            "8494/8494 [==============================] - 3s 411us/step - loss: 1.3736 - accuracy: 0.6892\n",
            "Epoch 89/200\n",
            "8494/8494 [==============================] - 3s 411us/step - loss: 1.3749 - accuracy: 0.6974\n",
            "Epoch 90/200\n",
            "8494/8494 [==============================] - 4s 425us/step - loss: 1.3725 - accuracy: 0.6873\n",
            "Epoch 91/200\n",
            "8494/8494 [==============================] - 4s 422us/step - loss: 1.3735 - accuracy: 0.6891\n",
            "Epoch 92/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3747 - accuracy: 0.7007\n",
            "Epoch 93/200\n",
            "8494/8494 [==============================] - 4s 414us/step - loss: 1.3729 - accuracy: 0.7001\n",
            "Epoch 94/200\n",
            "8494/8494 [==============================] - 4s 425us/step - loss: 1.3695 - accuracy: 0.6926\n",
            "Epoch 95/200\n",
            "8494/8494 [==============================] - 4s 420us/step - loss: 1.3729 - accuracy: 0.6926\n",
            "Epoch 96/200\n",
            "8494/8494 [==============================] - 4s 431us/step - loss: 1.3702 - accuracy: 0.6813\n",
            "Epoch 97/200\n",
            "8494/8494 [==============================] - 4s 430us/step - loss: 1.3714 - accuracy: 0.6935\n",
            "Epoch 98/200\n",
            "8494/8494 [==============================] - 4s 436us/step - loss: 1.3727 - accuracy: 0.6955\n",
            "Epoch 99/200\n",
            "8494/8494 [==============================] - 4s 433us/step - loss: 1.3692 - accuracy: 0.6905\n",
            "Epoch 100/200\n",
            "8494/8494 [==============================] - 4s 426us/step - loss: 1.3702 - accuracy: 0.6892\n",
            "Epoch 101/200\n",
            "8494/8494 [==============================] - 4s 424us/step - loss: 1.3687 - accuracy: 0.6846\n",
            "Epoch 102/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3688 - accuracy: 0.6908\n",
            "Epoch 103/200\n",
            "8494/8494 [==============================] - 4s 430us/step - loss: 1.3682 - accuracy: 0.6991\n",
            "Epoch 104/200\n",
            "8494/8494 [==============================] - 4s 426us/step - loss: 1.3664 - accuracy: 0.6997\n",
            "Epoch 105/200\n",
            "8494/8494 [==============================] - 4s 427us/step - loss: 1.3675 - accuracy: 0.6972\n",
            "Epoch 106/200\n",
            "8494/8494 [==============================] - 4s 426us/step - loss: 1.3668 - accuracy: 0.6978\n",
            "Epoch 107/200\n",
            "8494/8494 [==============================] - 4s 424us/step - loss: 1.3659 - accuracy: 0.7078\n",
            "Epoch 108/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3667 - accuracy: 0.6980\n",
            "Epoch 109/200\n",
            "8494/8494 [==============================] - 4s 436us/step - loss: 1.3661 - accuracy: 0.7023\n",
            "Epoch 110/200\n",
            "8494/8494 [==============================] - 4s 435us/step - loss: 1.3693 - accuracy: 0.6990\n",
            "Epoch 111/200\n",
            "8494/8494 [==============================] - 4s 431us/step - loss: 1.3637 - accuracy: 0.6946\n",
            "Epoch 112/200\n",
            "8494/8494 [==============================] - 4s 439us/step - loss: 1.3645 - accuracy: 0.7074\n",
            "Epoch 113/200\n",
            "8494/8494 [==============================] - 4s 430us/step - loss: 1.3691 - accuracy: 0.7051\n",
            "Epoch 114/200\n",
            "8494/8494 [==============================] - 4s 432us/step - loss: 1.3659 - accuracy: 0.7126\n",
            "Epoch 115/200\n",
            "8494/8494 [==============================] - 4s 431us/step - loss: 1.3647 - accuracy: 0.6925\n",
            "Epoch 116/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3679 - accuracy: 0.7050\n",
            "Epoch 117/200\n",
            "8494/8494 [==============================] - 4s 427us/step - loss: 1.3645 - accuracy: 0.7017\n",
            "Epoch 118/200\n",
            "8494/8494 [==============================] - 4s 423us/step - loss: 1.3615 - accuracy: 0.7040\n",
            "Epoch 119/200\n",
            "8494/8494 [==============================] - 4s 426us/step - loss: 1.3656 - accuracy: 0.6998\n",
            "Epoch 120/200\n",
            "8494/8494 [==============================] - 4s 427us/step - loss: 1.3629 - accuracy: 0.7070\n",
            "Epoch 121/200\n",
            "8494/8494 [==============================] - 4s 426us/step - loss: 1.3635 - accuracy: 0.7046\n",
            "Epoch 122/200\n",
            "8494/8494 [==============================] - 4s 428us/step - loss: 1.3627 - accuracy: 0.7046\n",
            "Epoch 123/200\n",
            "8494/8494 [==============================] - 4s 435us/step - loss: 1.3617 - accuracy: 0.7091\n",
            "Epoch 124/200\n",
            "8494/8494 [==============================] - 4s 418us/step - loss: 1.3616 - accuracy: 0.7016\n",
            "Epoch 125/200\n",
            "8494/8494 [==============================] - 4s 422us/step - loss: 1.3624 - accuracy: 0.7033\n",
            "Epoch 126/200\n",
            "8494/8494 [==============================] - 4s 424us/step - loss: 1.3625 - accuracy: 0.7039\n",
            "Epoch 127/200\n",
            "8494/8494 [==============================] - 4s 430us/step - loss: 1.3634 - accuracy: 0.7036\n",
            "Epoch 128/200\n",
            "8494/8494 [==============================] - 4s 427us/step - loss: 1.3628 - accuracy: 0.7130\n",
            "Epoch 129/200\n",
            "8494/8494 [==============================] - 4s 425us/step - loss: 1.3579 - accuracy: 0.7119\n",
            "Epoch 130/200\n",
            "8494/8494 [==============================] - 4s 423us/step - loss: 1.3597 - accuracy: 0.7087\n",
            "Epoch 131/200\n",
            "8494/8494 [==============================] - 4s 442us/step - loss: 1.3543 - accuracy: 0.7169\n",
            "Epoch 132/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3613 - accuracy: 0.7078\n",
            "Epoch 133/200\n",
            "8494/8494 [==============================] - 4s 421us/step - loss: 1.3573 - accuracy: 0.7044\n",
            "Epoch 134/200\n",
            "8494/8494 [==============================] - 4s 421us/step - loss: 1.3604 - accuracy: 0.7129\n",
            "Epoch 135/200\n",
            "8494/8494 [==============================] - 4s 422us/step - loss: 1.3617 - accuracy: 0.6997\n",
            "Epoch 136/200\n",
            "8494/8494 [==============================] - 4s 425us/step - loss: 1.3600 - accuracy: 0.7019\n",
            "Epoch 137/200\n",
            "8494/8494 [==============================] - 4s 423us/step - loss: 1.3578 - accuracy: 0.7050\n",
            "Epoch 138/200\n",
            "8494/8494 [==============================] - 4s 416us/step - loss: 1.3558 - accuracy: 0.7130\n",
            "Epoch 139/200\n",
            "8494/8494 [==============================] - 4s 422us/step - loss: 1.3544 - accuracy: 0.7118\n",
            "Epoch 140/200\n",
            "8494/8494 [==============================] - 4s 416us/step - loss: 1.3570 - accuracy: 0.7096\n",
            "Epoch 141/200\n",
            "8494/8494 [==============================] - 4s 421us/step - loss: 1.3556 - accuracy: 0.7119\n",
            "Epoch 142/200\n",
            "8494/8494 [==============================] - 4s 415us/step - loss: 1.3562 - accuracy: 0.7120\n",
            "Epoch 143/200\n",
            "8494/8494 [==============================] - 4s 426us/step - loss: 1.3547 - accuracy: 0.7153\n",
            "Epoch 144/200\n",
            "8494/8494 [==============================] - 4s 420us/step - loss: 1.3558 - accuracy: 0.7119\n",
            "Epoch 145/200\n",
            "8494/8494 [==============================] - 4s 446us/step - loss: 1.3554 - accuracy: 0.7178\n",
            "Epoch 146/200\n",
            "8494/8494 [==============================] - 4s 440us/step - loss: 1.3558 - accuracy: 0.7174\n",
            "Epoch 147/200\n",
            "8494/8494 [==============================] - 4s 424us/step - loss: 1.3579 - accuracy: 0.7149\n",
            "Epoch 148/200\n",
            "8494/8494 [==============================] - 4s 427us/step - loss: 1.3553 - accuracy: 0.7176\n",
            "Epoch 149/200\n",
            "8494/8494 [==============================] - 4s 420us/step - loss: 1.3576 - accuracy: 0.7126\n",
            "Epoch 150/200\n",
            "8494/8494 [==============================] - 4s 423us/step - loss: 1.3568 - accuracy: 0.7073\n",
            "Epoch 151/200\n",
            "8494/8494 [==============================] - 4s 423us/step - loss: 1.3562 - accuracy: 0.7194\n",
            "Epoch 152/200\n",
            "8494/8494 [==============================] - 4s 421us/step - loss: 1.3558 - accuracy: 0.7065\n",
            "Epoch 153/200\n",
            "8494/8494 [==============================] - 4s 428us/step - loss: 1.3535 - accuracy: 0.7160\n",
            "Epoch 154/200\n",
            "8494/8494 [==============================] - 4s 425us/step - loss: 1.3554 - accuracy: 0.7217\n",
            "Epoch 155/200\n",
            "8494/8494 [==============================] - 4s 428us/step - loss: 1.3556 - accuracy: 0.7163\n",
            "Epoch 156/200\n",
            "8494/8494 [==============================] - 4s 427us/step - loss: 1.3553 - accuracy: 0.7194\n",
            "Epoch 157/200\n",
            "8494/8494 [==============================] - 4s 428us/step - loss: 1.3535 - accuracy: 0.7222\n",
            "Epoch 158/200\n",
            "8494/8494 [==============================] - 4s 419us/step - loss: 1.3557 - accuracy: 0.7215\n",
            "Epoch 159/200\n",
            "8494/8494 [==============================] - 4s 430us/step - loss: 1.3527 - accuracy: 0.7230\n",
            "Epoch 160/200\n",
            "8494/8494 [==============================] - 4s 442us/step - loss: 1.3514 - accuracy: 0.7151\n",
            "Epoch 161/200\n",
            "8494/8494 [==============================] - 4s 449us/step - loss: 1.3491 - accuracy: 0.7222\n",
            "Epoch 162/200\n",
            "8494/8494 [==============================] - 4s 445us/step - loss: 1.3558 - accuracy: 0.7217\n",
            "Epoch 163/200\n",
            "8494/8494 [==============================] - 4s 445us/step - loss: 1.3501 - accuracy: 0.7197\n",
            "Epoch 164/200\n",
            "8494/8494 [==============================] - 4s 438us/step - loss: 1.3492 - accuracy: 0.7194\n",
            "Epoch 165/200\n",
            "8494/8494 [==============================] - 4s 435us/step - loss: 1.3503 - accuracy: 0.7269\n",
            "Epoch 166/200\n",
            "8494/8494 [==============================] - 4s 451us/step - loss: 1.3486 - accuracy: 0.7173\n",
            "Epoch 167/200\n",
            "8494/8494 [==============================] - 4s 471us/step - loss: 1.3524 - accuracy: 0.7149\n",
            "Epoch 168/200\n",
            "8494/8494 [==============================] - 4s 457us/step - loss: 1.3512 - accuracy: 0.7258\n",
            "Epoch 169/200\n",
            "8494/8494 [==============================] - 4s 445us/step - loss: 1.3485 - accuracy: 0.7259\n",
            "Epoch 170/200\n",
            "8494/8494 [==============================] - 4s 445us/step - loss: 1.3528 - accuracy: 0.7217\n",
            "Epoch 171/200\n",
            "8494/8494 [==============================] - 4s 436us/step - loss: 1.3501 - accuracy: 0.7291\n",
            "Epoch 172/200\n",
            "8494/8494 [==============================] - 4s 438us/step - loss: 1.3527 - accuracy: 0.7253\n",
            "Epoch 173/200\n",
            "8494/8494 [==============================] - 4s 440us/step - loss: 1.3512 - accuracy: 0.7242\n",
            "Epoch 174/200\n",
            "8494/8494 [==============================] - 4s 435us/step - loss: 1.3517 - accuracy: 0.7277\n",
            "Epoch 175/200\n",
            "8494/8494 [==============================] - 4s 436us/step - loss: 1.3490 - accuracy: 0.7213\n",
            "Epoch 176/200\n",
            "8494/8494 [==============================] - 4s 445us/step - loss: 1.3488 - accuracy: 0.7236\n",
            "Epoch 177/200\n",
            "8494/8494 [==============================] - 4s 443us/step - loss: 1.3487 - accuracy: 0.7192\n",
            "Epoch 178/200\n",
            "8494/8494 [==============================] - 4s 439us/step - loss: 1.3481 - accuracy: 0.7224\n",
            "Epoch 179/200\n",
            "8494/8494 [==============================] - 4s 444us/step - loss: 1.3471 - accuracy: 0.7368\n",
            "Epoch 180/200\n",
            "8494/8494 [==============================] - 4s 428us/step - loss: 1.3528 - accuracy: 0.7143\n",
            "Epoch 181/200\n",
            "8494/8494 [==============================] - 4s 435us/step - loss: 1.3477 - accuracy: 0.7210\n",
            "Epoch 182/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3471 - accuracy: 0.7249\n",
            "Epoch 183/200\n",
            "8494/8494 [==============================] - 4s 454us/step - loss: 1.3466 - accuracy: 0.7349\n",
            "Epoch 184/200\n",
            "8494/8494 [==============================] - 4s 427us/step - loss: 1.3468 - accuracy: 0.7251\n",
            "Epoch 185/200\n",
            "8494/8494 [==============================] - 4s 430us/step - loss: 1.3455 - accuracy: 0.7230\n",
            "Epoch 186/200\n",
            "8494/8494 [==============================] - 4s 433us/step - loss: 1.3462 - accuracy: 0.7204\n",
            "Epoch 187/200\n",
            "8494/8494 [==============================] - 4s 434us/step - loss: 1.3508 - accuracy: 0.7206\n",
            "Epoch 188/200\n",
            "8494/8494 [==============================] - 4s 424us/step - loss: 1.3439 - accuracy: 0.7273\n",
            "Epoch 189/200\n",
            "8494/8494 [==============================] - 4s 432us/step - loss: 1.3447 - accuracy: 0.7247\n",
            "Epoch 190/200\n",
            "8494/8494 [==============================] - 4s 427us/step - loss: 1.3486 - accuracy: 0.7239\n",
            "Epoch 191/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3459 - accuracy: 0.7215\n",
            "Epoch 192/200\n",
            "8494/8494 [==============================] - 4s 429us/step - loss: 1.3446 - accuracy: 0.7249\n",
            "Epoch 193/200\n",
            "8494/8494 [==============================] - 4s 435us/step - loss: 1.3444 - accuracy: 0.7265\n",
            "Epoch 194/200\n",
            "8494/8494 [==============================] - 4s 437us/step - loss: 1.3488 - accuracy: 0.7320\n",
            "Epoch 195/200\n",
            "8494/8494 [==============================] - 4s 442us/step - loss: 1.3438 - accuracy: 0.7233\n",
            "Epoch 196/200\n",
            "8494/8494 [==============================] - 4s 436us/step - loss: 1.3479 - accuracy: 0.7244\n",
            "Epoch 197/200\n",
            "8494/8494 [==============================] - 4s 438us/step - loss: 1.3472 - accuracy: 0.7271\n",
            "Epoch 198/200\n",
            "8494/8494 [==============================] - 4s 432us/step - loss: 1.3436 - accuracy: 0.7255\n",
            "Epoch 199/200\n",
            "8494/8494 [==============================] - 4s 435us/step - loss: 1.3452 - accuracy: 0.7250\n",
            "Epoch 200/200\n",
            "8494/8494 [==============================] - 4s 433us/step - loss: 1.3421 - accuracy: 0.7364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f1e41bdc4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeDGWSws_c2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = X_test.values\n",
        "Y_test = Y_test.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBJFHwFH-hrX",
        "colab_type": "code",
        "outputId": "113d2340-3dfc-428d-87ac-62b26b088140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, average_precision_score, f1_score\n",
        "y_pred_test = model.predict(X_test)\n",
        "y_pred_train = model.predict(X_train)\n",
        "conf_m_test = confusion_matrix(Y_test.argmax(axis=1), y_pred_test.argmax(axis=1))\n",
        "y_test_precision = average_precision_score(Y_test, y_pred_test)\n",
        "y_test_acc1 = accuracy_score(Y_test.argmax(axis=1), y_pred_test.argmax(axis=1))\n",
        "y_test_f1 = f1_score(Y_test.argmax(axis=1), y_pred_test.argmax(axis=1), average = 'weighted')\n",
        "y_train_f1 = f1_score(Y_train.argmax(axis=1), y_pred_train.argmax(axis=1), average = 'weighted')\n",
        "print(\"Precision of the Logistic Regression model in test set: \" + str(y_test_precision) + \"\\n Accuracy of the Logistic Regression Modelin test set: \" + str(y_test_acc1))\n",
        "print(\"f1 of the Logistic Regression model in test set: \" + str(y_test_f1))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision of the Logistic Regression model in test set: 0.3113456721226445\n",
            " Accuracy of the Logistic Regression Modelin test set: 0.6797865243495663\n",
            "f1 of the Logistic Regression model in test set: 0.6287490743685807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UfY3FzoSh_L",
        "colab_type": "code",
        "outputId": "3c6f9668-c55e-4701-9462-e443b4b59b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "y_train_precision = average_precision_score(Y_train, y_pred_train)\n",
        "y_train_acc1 = accuracy_score(Y_train.argmax(axis=1), y_pred_train.argmax(axis=1))\n",
        "print(\"Precision of the Logistic Regression model in test set: \" + str(y_test_precision) + \"\\n Accuracy of the Logistic Regression Modelin test set: \" + str(y_test_acc1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision of the Logistic Regression model in test set: 0.25005542865124253\n",
            " Accuracy of the Logistic Regression Modelin test set: 0.6490993995997332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmovHnTkkmo8",
        "colab_type": "code",
        "outputId": "1d94ae53-993a-49b4-f533-96823f1dff24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout\n",
        "# Set CNN model\n",
        "# Our system of layers => [[Conv2D -> relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
        "input_shape = (64, 64, 3)\n",
        "num_classes = 7\n",
        "\n",
        "\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Conv2D(10, kernel_size = (3, 3), activation = 'relu', padding = 'Same', input_shape = input_shape))\n",
        "model_cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model_cnn.add(Dropout(0.25))\n",
        "model_cnn.add(Conv2D(20, kernel_size = (5, 5), activation = 'relu', padding = 'Same'))\n",
        "model_cnn.add(MaxPooling2D(pool_size = (3, 3)))\n",
        "model_cnn.add(Dropout(0.25))\n",
        "model_cnn.add(Conv2D(30, kernel_size = (7, 7), activation = 'relu', padding = 'Same'))\n",
        "model_cnn.add(MaxPooling2D(pool_size = (4, 4)))\n",
        "model_cnn.add(Dropout(0.25))\n",
        "\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(120, activation='relu'))\n",
        "model_cnn.add(Dropout(0.2))\n",
        "model_cnn.add(Dense(64, activation ='relu'))\n",
        "model_cnn.add(Dropout(0.2))\n",
        "model_cnn.add(Dense(num_classes, activation='softmax'))\n",
        "model_cnn.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 64, 64, 10)        280       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 10)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 32, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 20)        5020      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 20)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 10, 10, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 30)        29430     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 30)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 2, 30)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 120)               14520     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                7744      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 57,449\n",
            "Trainable params: 57,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH2ojrsEnhAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmfyozuJXP_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train3D = np.reshape(X_train, (X_train.shape[0], 64, 64, 3))\n",
        "X_test3D = np.reshape(X_test, (X_test.shape[0], 64, 64, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D72wRusZV1tM",
        "colab_type": "code",
        "outputId": "ebc1493c-1e3b-489f-cb4c-f181c57ddb8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_cnn.fit(X_train3D, Y_train, batch_size = 32, epochs = 200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "8494/8494 [==============================] - 41s 5ms/step - loss: 2.3068 - accuracy: 0.6563\n",
            "Epoch 2/200\n",
            "8494/8494 [==============================] - 41s 5ms/step - loss: 1.0070 - accuracy: 0.6665\n",
            "Epoch 3/200\n",
            "8494/8494 [==============================] - 41s 5ms/step - loss: 0.9763 - accuracy: 0.6664\n",
            "Epoch 4/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.9571 - accuracy: 0.6706\n",
            "Epoch 5/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.9391 - accuracy: 0.6668\n",
            "Epoch 6/200\n",
            "8494/8494 [==============================] - 41s 5ms/step - loss: 0.9374 - accuracy: 0.6700\n",
            "Epoch 7/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.9165 - accuracy: 0.6701\n",
            "Epoch 8/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.9190 - accuracy: 0.6704\n",
            "Epoch 9/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8981 - accuracy: 0.6728\n",
            "Epoch 10/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8957 - accuracy: 0.6765\n",
            "Epoch 11/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8884 - accuracy: 0.6779\n",
            "Epoch 12/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8785 - accuracy: 0.6811\n",
            "Epoch 13/200\n",
            "8494/8494 [==============================] - 42s 5ms/step - loss: 0.8758 - accuracy: 0.6822\n",
            "Epoch 14/200\n",
            "8494/8494 [==============================] - 41s 5ms/step - loss: 0.8689 - accuracy: 0.6837\n",
            "Epoch 15/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8633 - accuracy: 0.6865\n",
            "Epoch 16/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8567 - accuracy: 0.6825\n",
            "Epoch 17/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8515 - accuracy: 0.6850\n",
            "Epoch 18/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8525 - accuracy: 0.6888\n",
            "Epoch 19/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8476 - accuracy: 0.6872\n",
            "Epoch 20/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8377 - accuracy: 0.6928\n",
            "Epoch 21/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8389 - accuracy: 0.6885\n",
            "Epoch 22/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8300 - accuracy: 0.6930\n",
            "Epoch 23/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8240 - accuracy: 0.6953\n",
            "Epoch 24/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8301 - accuracy: 0.6953\n",
            "Epoch 25/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8296 - accuracy: 0.6941\n",
            "Epoch 26/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8215 - accuracy: 0.6939\n",
            "Epoch 27/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8081 - accuracy: 0.6999\n",
            "Epoch 28/200\n",
            "8494/8494 [==============================] - 43s 5ms/step - loss: 0.8093 - accuracy: 0.7007\n",
            "Epoch 29/200\n",
            "8494/8494 [==============================] - 41s 5ms/step - loss: 0.8041 - accuracy: 0.7027\n",
            "Epoch 30/200\n",
            "8494/8494 [==============================] - 41s 5ms/step - loss: 0.8080 - accuracy: 0.6976\n",
            "Epoch 31/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.7949 - accuracy: 0.7013\n",
            "Epoch 32/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.8003 - accuracy: 0.7020\n",
            "Epoch 33/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.7844 - accuracy: 0.7036\n",
            "Epoch 34/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.7870 - accuracy: 0.7084\n",
            "Epoch 35/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.7847 - accuracy: 0.7046\n",
            "Epoch 36/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.7808 - accuracy: 0.7070\n",
            "Epoch 37/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.7770 - accuracy: 0.7119\n",
            "Epoch 38/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.7764 - accuracy: 0.7098\n",
            "Epoch 39/200\n",
            "8494/8494 [==============================] - 40s 5ms/step - loss: 0.7836 - accuracy: 0.7052\n",
            "Epoch 40/200\n",
            "  96/8494 [..............................] - ETA: 40s - loss: 0.7824 - accuracy: 0.7188"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMce7hVaWCF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
